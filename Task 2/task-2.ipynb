{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":31193,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Step 1: Install and import required packages\n\n# Installing NLTK (for NLP preprocessing)\n!pip install nltk\n\n# Importing all necessary libraries\nimport nltk                                        # NLP preprocessing tools\nfrom nltk.corpus import stopwords                  # stopwords list\nfrom nltk.tokenize import word_tokenize            # word tokenization\nimport string                                       # punctuation list\nfrom sklearn.feature_extraction.text import TfidfVectorizer   # text → vector conversion\nfrom sklearn.metrics.pairwise import cosine_similarity         # similarity score\n\n# Downloading essential NLTK datasets\nnltk.download('punkt')\nnltk.download('stopwords')\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-11-29T12:12:11.935670Z","iopub.execute_input":"2025-11-29T12:12:11.936125Z","iopub.status.idle":"2025-11-29T12:12:15.054874Z","shell.execute_reply.started":"2025-11-29T12:12:11.936104Z","shell.execute_reply":"2025-11-29T12:12:15.054135Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (3.9.2)\nRequirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk) (8.3.0)\nRequirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk) (1.5.2)\nRequirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk) (2025.11.3)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk) (4.67.1)\n","output_type":"stream"},{"name":"stderr","text":"[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n","output_type":"stream"},{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}],"execution_count":10},{"cell_type":"code","source":"# Step 2: Creating FAQ dataset (questions + answers)\n\nfaqs = {\n    \"What is AI?\": \"Artificial Intelligence allows machines to perform tasks that normally require human intelligence.\",\n    \"What is Machine Learning?\": \"Machine learning enables computers to learn from data without being explicitly programmed.\",\n    \"What is Deep Learning?\": \"Deep learning uses neural networks with multiple layers to learn complex patterns.\",\n    \"What is Data Science?\": \"Data science involves collecting, cleaning, analyzing, and interpreting large amounts of data.\",\n    \"What is Python used for?\": \"Python is used for AI, data science, automation, web development, and more.\",\n    \"What is NLP?\": \"Natural Language Processing allows computers to understand and generate human language.\",\n}\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-29T12:12:26.217401Z","iopub.execute_input":"2025-11-29T12:12:26.217738Z","iopub.status.idle":"2025-11-29T12:12:26.222580Z","shell.execute_reply.started":"2025-11-29T12:12:26.217711Z","shell.execute_reply":"2025-11-29T12:12:26.221739Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"# Step 3: Preprocessing text using NLTK\n\n\nstop_words = set(stopwords.words('english'))        # stopwords set for faster lookup\npunct = string.punctuation                          # punctuation list\n\ndef preprocess(text):\n    text = text.lower()                             # convert to lowercase\n    tokens = word_tokenize(text)                    # tokenize into words\n    tokens = [t for t in tokens if t not in punct]  # remove punctuation\n    tokens = [t for t in tokens if t not in stop_words]  # remove stopwords\n    return \" \".join(tokens)                         # rejoin tokens as clean text\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-29T12:12:31.917275Z","iopub.execute_input":"2025-11-29T12:12:31.917793Z","iopub.status.idle":"2025-11-29T12:12:31.923260Z","shell.execute_reply.started":"2025-11-29T12:12:31.917769Z","shell.execute_reply":"2025-11-29T12:12:31.922444Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"# Step 4: Preprocessing all FAQ questions\n\nquestions = list(faqs.keys())              # extracting all FAQ questions\nanswers = list(faqs.values())              # extracting all FAQ answers\n\nclean_questions = [preprocess(q) for q in questions]   # preprocessed questions\nclean_questions\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-29T12:12:45.990023Z","iopub.execute_input":"2025-11-29T12:12:45.990624Z","iopub.status.idle":"2025-11-29T12:12:45.996675Z","shell.execute_reply.started":"2025-11-29T12:12:45.990600Z","shell.execute_reply":"2025-11-29T12:12:45.995782Z"}},"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"['ai',\n 'machine learning',\n 'deep learning',\n 'data science',\n 'python used',\n 'nlp']"},"metadata":{}}],"execution_count":14},{"cell_type":"code","source":"# Step 5: Converting preprocessed FAQ questions to TF-IDF vectors\n\nvectorizer = TfidfVectorizer()             # transformer to convert text → vectors\nX = vectorizer.fit_transform(clean_questions)  # vectorizing FAQ questions\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-29T12:12:54.321685Z","iopub.execute_input":"2025-11-29T12:12:54.321925Z","iopub.status.idle":"2025-11-29T12:12:54.329231Z","shell.execute_reply.started":"2025-11-29T12:12:54.321909Z","shell.execute_reply":"2025-11-29T12:12:54.328584Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"# Step 6: Matching user query with most similar FAQ\n\ndef chatbot_response(user_query):\n    # Preprocess user question\n    clean_query = preprocess(user_query)\n    \n    # Convert to TF-IDF vector\n    query_vec = vectorizer.transform([clean_query])\n    \n    # Calculate cosine similarity\n    scores = cosine_similarity(query_vec, X).flatten()\n    \n    # Get best match index\n    best_match = scores.argmax()\n    \n    # Return answer for closest matching FAQ\n    return answers[best_match]\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-29T12:13:01.103874Z","iopub.execute_input":"2025-11-29T12:13:01.104535Z","iopub.status.idle":"2025-11-29T12:13:01.108624Z","shell.execute_reply.started":"2025-11-29T12:13:01.104508Z","shell.execute_reply":"2025-11-29T12:13:01.107941Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"# Step 7: Chatbot interaction loop\n\nprint(\"Chatbot is ready! Ask your questions (type 'quit' to stop)\")\n\nwhile True:\n    user = input(\"You: \")\n    if user.lower() == \"quit\":\n        print(\"Chatbot: Goodbye!\")\n        break\n\n    response = chatbot_response(user)\n    print(\"Chatbot:\", response)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-29T12:13:46.699466Z","iopub.execute_input":"2025-11-29T12:13:46.700138Z","iopub.status.idle":"2025-11-29T12:14:21.976078Z","shell.execute_reply.started":"2025-11-29T12:13:46.700116Z","shell.execute_reply":"2025-11-29T12:14:21.975284Z"}},"outputs":[{"name":"stdout","text":"Chatbot is ready! Ask your questions (type 'quit' to stop)\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"You:  What does AI do?\n"},{"name":"stdout","text":"Chatbot: Artificial Intelligence allows machines to perform tasks that normally require human intelligence.\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"You:  What does a Deep leaning model use? \n"},{"name":"stdout","text":"Chatbot: Deep learning uses neural networks with multiple layers to learn complex patterns.\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"You:  quit\n"},{"name":"stdout","text":"Chatbot: Goodbye!\n","output_type":"stream"}],"execution_count":18},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}